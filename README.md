# ðŸ”· Adaptive Resonance Optimization (ARO)

> **Learning law for optimization**:  
> ARO = **Gradient descent + Adaptive Resonance dynamics**.  
> It extends optimizers (SGD/AdamW) with **resonant attractors** and **vigilance-gated memory**, yielding stable but plastic learning.

---

## ðŸ“– Overview

Traditional optimizers (SGD, Adam, AdamW) treat learning as **filtered gradient descent**:
- Parameters `Î¸` updated by gradients `g`.
- Momentum and variance tracking = **1st-order IIR filters**.
- Great for smoothing noise, but **forgetful**: no structural memory, risk of catastrophic forgetting.

**Adaptive Resonance Theory (ART)**, from Grossberg, defines learning laws as **differential equations**:
- Prototypes `w_j` evolve toward matched hidden states.
- Hidden states `h` resonate with prototypes.
- Vigilance `Ï` gates whether to update or allocate new memory.
- Balances **stability** (donâ€™t overwrite) and **plasticity** (learn new).

**ARO unifies these two views**:  
ðŸ‘‰ Error-driven gradient descent **plus** resonance-driven prototype dynamics.

---

## âš™ï¸ System Model

State:
```

x\_t = \[ Î¸\_t, h\_t, Î±\_t, Î¼\_t, Ïƒ\_t, W\_t ]

```
- `Î¸_t` â€“ plant parameters (DSP knobs, NN weights, etc.)
- `h_t` â€“ optimizer buffers (e.g. momentum)
- `Î±_t, Î¼_t` â€“ adaptive hyperparameters (LR, momentum)
- `Ïƒ_t` â€“ dither strength
- `W_t = { w_j }` â€“ ART prototypes (memory traces)

Feedback:
```

y\_t = \[ â„“\_t, r\_t ]

```
- `â„“_t` â€“ loss  
- `r_t` â€“ optional reward  

---

## ðŸ”¹ Learning Laws

### 1. Error-driven path (AdamW-style)
```

m\_t = Î¼ m\_{t-1} + (1-Î¼) g\_t      # momentum = 1st-order IIR
u\_t = Î± Â· precondition(m\_t)      # control action
Î¸\_{t+1} = Î¸\_t - u\_t + Ïƒ D(Î¸)Î·\_t  # update + shaped dither

```

### 2. Resonance-driven path (ART-style)
```

h*\_{t+1} = h*\_t + Î» (w\_j - h*\_t)              # hidden state pulled to prototype
w\_j â† w\_j + Î· ((h* âˆ§ w\_j) - w\_j)              # prototype update law
M\_j = |h\* âˆ§ w\_j| / |h\*| â‰¥ Ï  ?  update : new  # vigilance gate

```

### 3. Coupling (two choices)
- **Regularizer**:
```

L\_total = L\_task + Î»\_ART ||h\* - w\_j||^2

```
- **Feedback correction**:
```

Î¸\_{t+1} = Î¸\_t - u\_t + Î² (h*\_{t+1} - h*\_t)

````

---

## ðŸŽ› Application to DSP Plants

- **Plant**: differentiable DSP chain (oscillators, filters, envelopes, effects).  
- **Embedding `h*`**: learned features (STFT/mel, small encoder).  
- **Prototypes `w_j`**: represent stable timbral/feature regimes.  
- **Vigilance `Ï`**: spawns new prototypes for novel sounds.  
- **Coupling**: resonance loss aligns features with prototypes; error loss drives task learning.  

---

## ðŸ›  Design Rules

- Clamp gains: `Î± âˆˆ [Î±_min, Î±_max]`, `Î¼ âˆˆ [0,1)`, `Ïƒ â‰ª 1`.  
- Dampen LR when loss variance is high.  
- Use small ART weight (`Î»_ART ~ 1e-4`) in regression.  
- Prototype LR `Î· ~ 1e-3 â€¦ 1e-2`.  
- Vigilance `Ï âˆˆ [0.7, 0.9]` â†’ controls memory granularity.  

---

## ðŸ“Š Comparison

| Aspect              | AdamW                             | ARO (AdamW + ART)                    |
|---------------------|-----------------------------------|--------------------------------------|
| Gradient smoothing  | EMA of g, EMA of gÂ²               | Same                                 |
| Step-size scaling   | Variance-normalized               | Same (inherits AdamW)                |
| Weight decay        | Explicit, decoupled               | Can add, not core                    |
| Memory              | Buffers only (m,v)                | Explicit prototypes `w_j`            |
| Nonlinearity        | Smooth (all filters)              | Vigilance = switching nonlinearity   |
| Stability           | By normalization/damping          | By prototypes as attractors          |
| Plasticity          | LR scheduling only                | Vigilance-spawned new prototypes     |

---

## âœ… Why It Matters

- **Stabilityâ€“Plasticity balance**: prototypes anchor learned states, vigilance handles novelty.  
- **Continual learning**: no catastrophic forgetting; optimizer itself preserves structure.  
- **Control-theoretic grounding**: behaves like a 2-pole system (momentum + resonance).  
- **General**: wraps around *any plant* (DSP chain, NN, controller).  

---

## ðŸš€ Quick Start (PyTorch)

```python
model = MyDSPPlant()
opt = AdamWAdaptiveResonance(
  model.parameters(),
  lr=1e-3, betas=(0.9,0.999), weight_decay=1e-2,
  resonance_weight=1e-3, vigilance=0.8, proto_lr=5e-3
)

for x, y in data:
  y_pred, h = model(x)
  loss = mse(y_pred, y) + opt.resonance_weight * opt.resonance_loss(h)
  loss.backward()
  opt.step(h_star=h)
  opt.zero_grad()
````

---

## ðŸ“– Citation-style Thesis

> **Adaptive Resonance Optimization (ARO)** augments gradient descent with resonance dynamics, turning the optimizer into a **2nd-order resonant control system**. Prototypes serve as explicit attractors in representation space, and vigilance regulates stabilityâ€“plasticity. This reframes optimization as not just error minimization, but as a **dynamical system with memory**.

---

```

